---
grave: https://zju-turing.github.io/TuringCoursesGrave/major_basic/ai_basic/
---

# 人工智能引论

!!! note
    22 级开始从人工智能基础改名为了人工智能引论。原来的人工智能基础仍开课，面向的是非图灵班的同学（两门课教的内容和考的都差不多，差不多就是计逻和数逻的关系）。

## 课程学习内容

围绕吴飞老师的《人工智能导论：模型与算法》这本书讲解人工智能的领域的一些基础知识：逻辑推理、搜索求解、监督学习、无监督学习、深度学习、强化学习、博弈论等内容。22 级这本书只是作为参考，期末出题主要根据 PPT 出。不过事实上 PPT 内容和这本书内容差不多，PPT 例子更多一些，以及相较于书删减了一些复杂的内容。听说之后会出一本新书作为教材。

课程内容看似较多，但实际要求掌握、考试考的基本都是概念，重点在于理解以及背书。会有 5-8 次实验（21 级是 7 次，22 级是 5 次），均使用 python 语言，设计较为不合理，基本达到实验目标即可，不用太深究。在课程改名为人工智能引论之后，实验数量减少了，并且不需要写实验报告，可以说是一大改进。22 级的 5 次实验具体为：

- 用深度优先搜索求解八皇后问题的所有解
- 使用蒙特卡洛搜索算法实现一个下黑白棋的 AI
- 使用 K-means 算法实现异常检测
- 实现对手写数字的识别和垃圾分类（这个 lab 看起来很难，但事实上代码全都写好了，只需要调参数） 
- 使用 Deep Q-learning 算法实现自动走迷宫的机器人

以下是一份比较简略的课程（考试）大纲，其中有部分课程内容没有被包含，主要是8-10章的内容，也不保证之后的大纲与此相同，仅供参考。

建议在系统复习一遍后过一遍大纲，看看有没有遗漏的知识点或者说不出来的概念。

??? note "课程内容大纲"

    1. 介绍人工智能的发展现状等基本概论
    2. 逻辑与推理
        - 逻辑，与、或、异或，全称量词、存在量词的消去、引入，这部分与离散数学知识重合
        - 知识图谱推理：三元组，两个对象+关系，
        - FOIL算法，路径排序算法
        - 原子命题，复合命题
        - 推理手段，推导过程，谓词逻辑（关系）
        - 概率图 贝叶斯有向，马尔可夫无向，局部马尔可夫性，概率计算
        - 因果，混淆偏差（前因）、选择偏差（后果），干预，反事实
    3. 搜索求解
        - 状态、动作、状态转移、路径/代价
        - 搜索算法的时空复杂度、完备性、最优性
        - 搜索算法的启发函数、评价函数
        - 贪婪搜索，A*搜索，可容性、一致性
        - minmax对抗、$\alpha-\beta$ 剪枝
        - 蒙特卡洛树搜索、$\epsilon$ 贪心，UCB1，上限置信区间算法
    4. 机器学习
        - 有监督、无监督学习的区别
        - 3个集的区别：训练集、验证集、测试集
        - 3种损失函数：均方差，交叉熵，0-1损失
        - 2种风险;经验风险,期望风险
        - 4个率
            - 准确率，错误率，精确率，召回率
            - 精确率：被预测为P的里面真为P的
            - 召回率：所有真P中被预测为P的
            - F1会算出来，精确率和召回率的调和平均
        - logistic非线性回归的计算，sigmoid,tanh,relu的区别、特点
        - k均值聚类的步骤
        - LDA与PCA的区别与对比
        - eigenface的流程
    5. 深度学习
        - 感知机与深度神经网络，全连接、反向传播、梯度下降
        - Relu, sigmoid, softmax
        - 反推某个变量分的梯度，要会推，反传，链式法则
        - 池化层，会计算池化后向量大小，局部感知，参数共享，选择性感受野
        - 梯度消失、梯度爆炸
        - 循环神经网络，长短时记忆模型LSTM
        - 注意力，自注意力机制
        - 正则化、过拟合、dropout
        - 词向量的生成
    6. 强化学习
        - 价值和奖励的区别辨析
        - 监督学习、无监督学习、强化学习的横向对比
        - 单步vs序贯性
        - 离散马尔科夫链
        - 奖励机制，折扣因子
        - MDP马尔可夫决策过程
        - 轨迹、分段、持续问题、片段
        - 策略函数、价值函数、动作-价值函数，贝尔曼方程
        - 基于策略的和基于价值的强化学习区别
        - DP算法，蒙特卡洛算法、TD算法
        - Q学习，怎样更新Q值，探索和利用
        - DQN引入的新机制
        - actor-critic算法
    7. 人工智能博弈
        - 囚徒困境、最优解
        - 纳什均衡。期望收益相同
        - 虚拟遗憾最小化算法，例子：石头剪刀布
        - 双边匹配，单边匹配

## 授课老师

=== "章敏"
    老师人很好，尽管 22 级每次到课人数都是个位数还是把出勤分都给大家算满了，并且说如果对这门课/老师有什么意见欢迎跟她提出（虽然大概是没有人去提的）。讲课基本是在读 PPT。给分比较好，只要实验正常完成，平时分就能拿到比较高的分数。
=== "吴飞"
    上课是很认真地读ppt，老师是教材的作者，因此对教授内容有自己比较详尽的解释，但语音语调挺催眠的。又因为ppt上教的和实验关系不大，会出现听懂了课上讲的内容但做实验摸黑的情况，且课上会时不时冒出“新书是怎么写出来的”“我的一个学生怎么怎么样”的题外话，所以大家不怎么爱听课。

    整个学期点了两次名（一个一个叫名字，非电子点名，不会提前提醒），算入考勤分。实验分好像是根据实验网站的的一套评分逻辑给的，比如说黑白棋会根据和ai对战，以及学生的作业互相对战的结果评分。期末题考概念，所以答案比较确定，判卷应该没怎么放水。
=== "杨易"
    杨易老师是国际上很有名的人工智能领域专家，有许多研究成果。他的课虽然挂名是杨老师，但是在 23-24 秋冬学期的 16 周课程中，本人只来上了 3 周的课（可能是因为比较忙），剩下的部分是其学生朱霖潮老师来讲授。总的来说，杨易老师讲课风趣幽默、引人入胜，朱霖潮老师讲课严谨认真、互动性强（实际上是他希望有互动，因为单纯讲课效果略催眠）。
    
    在 23-24 秋冬学期的课程中，杨老师的课只正式点过（计入考核）一次名，是在倒数第三节课时提前提醒的，平常几乎不点名，同时实验课的助教也比较负责。期末考试之前会有一至两节复习课，给分方面反馈普遍还不错。

## 分数构成

出勤（5%）+ 实验（35%）+ 期末考试（60%）

## 参考笔记

- 中国大学 mooc 上「人工智能导论：模型与算法」课程测试题与答案：https://blog.csdn.net/a66666_/article/details/105123032
- xg 的复习笔记（都是概念抄书）：https://note.tonycrane.cc/cs/ai/basic/

## 学习建议

实验建议不要拖 ddl，尽早完成。实验设计基本都不怎么合理，体现在无从下手、测试不全等等方面。遇到问题了找助教或者和同学们讨论讨论。完成目标就可以了，不需要深究，不必要求结果达到完美，没必要在这种课程这种实验上浪费太多时间。

22 级期末考试是填空（40）+ 单选（30）+ 简答（30）。填空题 1 分一个共 40 个，基本就是 PPT 上的一段文字挖空填，会给备选项，类似完形填空；单项选择题 1.5 分一个共 20 个；大题 5 分一个共 6 个。可以说考察的大部分是概念，有少部分计算但并不困难，有不少是 PPT 上面的例子，复习的时候需要特别注意。总体而言考察的很均匀，无论是填空选择还是大题，基本上考试范围内的每一章的重点都会考。难度不高，主要是看书记概念。如果想要拿到还过得去的分数，PPT 还是需要认真过一遍，熟悉重要的概念和 PPT 上面的例子。98 上面有 22 级的历年卷回忆，可以拿来检查一下自己复习的效果。

笔者和同学注意到黄正行老师在 22 级人工智能基础的最后一节复习课上有划重点，并附带部分真题讲解，因为这两门课差不多，所以可以在期末周的时候关注一下。考试题型和上面参考资料中的 mooc 的题目有一定相似度，也可以参考。
