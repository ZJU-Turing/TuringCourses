# 信息理论

## 课程学习内容

信息论是以前信工的必修，现在变成了工高的课。

信息论是服务于通信的应用数学，将生活中的信息载体（如文字）建模成随机变量序列，以此和概率论挂钩。然后，用概率作为工具解决几个问题：

1. 如何高效地编码：输入一个随机变量序列，需要多少 bit 才能做到几乎无差错地表示（几乎指的是当序列长度趋向于正无穷时，出错的概率趋于 0）这个理论下限对应香农第一定理；
2. 如何高效地传输：对一个有噪声的信道，我们需要更多的比特才能完成几乎无差错的传输（给定一个输入序列和一个有噪声信道，需要找到一对编码器/译码器，使得编码尽可能地短）这个理论上限对应香农第二定理；
3. 如何高效地有损压缩：给定一个误差 D 和一个失真度量函数 d（类似距离函数，用来衡量压缩结果相对于输入的偏离程度），要找出一对编码译码器，使在误差期望小于 D 的前提下，编码尽可能地短。

### 先修要求

学过数分 I 的同学都能学。名义上是高级概率论，实际上几乎仅用到了概率论中的切比雪夫不等式，以及高中概率论，这些不需要提前准备。另外，极限思想对理解当输入序列长度充分大时，他们几乎都是典型列（一种特殊的输入序列）有帮助。

## 任课教师

=== "余官定"

    余老师上课清晰且幽默，强调物理意义帮助理解，对于工科生十分友好。同时余老师也会根据工科同学的需要进行拓展和删减，25年也有一节课由余老师博士生讲解信息瓶颈理论，信息论在ML中的一个应用。

## 参考资料

### 课程教材

- *《信息论与编码》*（仇佩亮）：比较清晰易懂，适当时会用文字和图表帮助理解，内容同 PPT。

### 推荐书单

- Thomas, M. T. C. A. J., & Joy, A. T. (2006). *Elements of information theory. Wiley-Interscience*.

    很厚一本，虽然是非常经典的书，但并不推荐初学者使用，此书过于啰嗦，容易让初学者抓不到重点。可以把它当作参考书或工具书。

- Alajaji, F., & Chen, P. N. (2018). *An introduction to single-user information theory*. Singapore: Springer.

    对于希望自学信息论的同学，个人推荐这本。有配套课程：台湾交通大学陈伯宁老师的《[消息理論](https://ocw.nycu.edu.tw/?course_page=all-course%2Fcollege-of-electrical-and-computer-engineering%2F%E6%B6%88%E6%81%AF%E7%90%86%E8%AB%96-information-theory-107%E5%AD%B8%E5%B9%B4%E5%BA%A6-%E9%9B%BB%E6%A9%9F%E5%B7%A5%E7%A8%8B%E5%AD%B8%E7%B3%BB-%E9%99%B3%E4%BC%AF%E5%AF%A7%E8%80%81%E5%B8%AB)》：[YouTube](https://www.youtube.com/playlist?list=PLj6E8qlqmkFsWS54o6gNWeDGXeI7c3eUd) | [B 站](https://www.bilibili.com/video/BV14N41197bN)，该课程理论扎实、深入浅出，学之体验不错。
